{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "conv_2D-with-modularity.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nakib103/pancancer_classification/blob/master/conv_2D_with_modularity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzGoEQohHH12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import packages\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import math\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lD1TdNixHQY1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0f470367-b474-4a69-c819-710c62fa186a"
      },
      "source": [
        "# run this cell to mount your Google Drive.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1o0LFMSHVcu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load data and label\n",
        "\n",
        "data = pd.read_pickle(\"/content/drive/My Drive/data/data_df.pkl\")\n",
        "label = pd.read_pickle(\"/content/drive/My Drive/data/label_df.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V64tTG2fHvuF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_data(data):\n",
        "  # create data variable from loaded data\n",
        "  data_log_transformed = data.apply(lambda x: np.log2(x + 1))\n",
        "\n",
        "  return data_log_transformed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59zyvfsn_WKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shuffle_data(data, label):\n",
        "  ## same patient check\n",
        "  # generate shuffled index\n",
        "  shuffled_index = np.random.permutation(data.index)\n",
        "\n",
        "  # shiffle data and label\n",
        "  data_shuffled = data.reindex(shuffled_index)\n",
        "  label_shuffled = label.reindex(shuffled_index)\n",
        "\n",
        "  return data_shuffled, label_shuffled"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYZruUsW_3WG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_pd_to_np(data, shape):\n",
        "  # convert dataframe to numpy array\n",
        "  x = data.iloc[:].values\n",
        "\n",
        "  # pad the training postion with zero\n",
        "  x = np.pad(x, ((0, 0),(0, shape[0] * shape[1] - x.shape[1])), 'constant', constant_values=0)\n",
        "\n",
        "  # reshape to 2D\n",
        "  x = np.reshape(x, (x.shape[0], 1, shape[0], shape[1]))\n",
        "\n",
        "  # normalize data to [0, 255] range\n",
        "  x = ( x / np.max(x) ) * 255\n",
        "\n",
        "  # convert data format to integer\n",
        "  x = x.astype(int)\n",
        "  \n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yq5WUe1_-6o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def label_pd_to_np(label):\n",
        "  # create label variable from loaded label\n",
        "  y = label.iloc[:].values\n",
        "\n",
        "  for id_y, lab_y in enumerate(y):\n",
        "    for id_class, lab_class in enumerate(classes):\n",
        "      if lab_y[0] == lab_class:\n",
        "        y[id_y] = id_class\n",
        "        break\n",
        "  print(y.shape)\n",
        "  y = y[:,0]\n",
        "  y = to_categorical(y)\n",
        "\n",
        "  return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNnCyHkBXwke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# store the 2D data and corresponding label\n",
        "\n",
        "# np.save('/content/drive/My Drive/data/data_np_2D.npy', x)\n",
        "# np.save('/content/drive/My Drive/data/label_np_2D.npy', y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNkWd2gGIsPR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2855959f-3f42-4cca-9f67-a005715026d3"
      },
      "source": [
        "# custom losss function - wighted categorical-crossentropy\n",
        "## need testing\n",
        "\"\"\"\n",
        "A weighted version of categorical_crossentropy for keras (2.0.6). This lets you apply a weight to unbalanced classes.\n",
        "@url: https://gist.github.com/wassname/ce364fddfc8a025bfab4348cf5de852d\n",
        "@author: wassname\n",
        "\"\"\"\n",
        "from keras import backend as K\n",
        "def weighted_categorical_crossentropy(weights):\n",
        "    \"\"\"\n",
        "    A weighted version of keras.objectives.categorical_crossentropy\n",
        "    \n",
        "    Variables:\n",
        "        weights: numpy array of shape (C,) where C is the number of classes\n",
        "    \n",
        "    Usage:\n",
        "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
        "        loss = weighted_categorical_crossentropy(weights)\n",
        "        model.compile(loss=loss,optimizer='adam')\n",
        "    \"\"\"\n",
        "    \n",
        "    weights = K.variable(weights)\n",
        "        \n",
        "    def loss(y_true, y_pred):\n",
        "        # scale predictions so that the class probas of each sample sum to 1\n",
        "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
        "        # clip to prevent NaN's and Inf's\n",
        "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
        "        # calc\n",
        "        loss = y_true * K.log(y_pred) * weights\n",
        "        loss = -K.sum(loss, -1)\n",
        "        return loss\n",
        "    \n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cll-BqsxI9Xh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model definition\n",
        "def define_model(input_shape, num_of_class):\n",
        "  regularizer = regularizers.l1_l2(l1=0.000, l2=0.000)\n",
        "  x = input_shape[0]\n",
        "  y = input_shape[1]\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), data_format='channels_first', input_shape=(1, x, y), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), data_format='channels_first'))\n",
        "  model.add(Dropout(rate = 0.1))\n",
        "\n",
        "  model.add(Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), activation='relu', data_format='channels_first'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), data_format='channels_first'))\n",
        "  model.add(Dropout(rate = 0.1))\n",
        "\n",
        "  model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), activation='relu', data_format='channels_first'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), data_format='channels_first'))\n",
        "  model.add(Dropout(rate = 0.1))\n",
        "            \n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(units =1024, activation = 'relu', kernel_regularizer = regularizer))\n",
        "  model.add(Dense(units = 1024, activation = 'relu', kernel_regularizer = regularizer))\n",
        "  model.add(Dense(units = 512, activation = 'relu', kernel_regularizer = regularizer))\n",
        "            \n",
        "  model.add(Dense(units = num_of_class, activation = 'softmax'))\n",
        "\n",
        "  print(model.summary())\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KHM_MeZDGU-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate data and label\n",
        "def generate_dataset(data, label, shape):\n",
        " \n",
        "  data = preprocess_data(data)\n",
        "  data, label = shuffle_data(data, label)\n",
        "  data = data_pd_to_np(data, shape)\n",
        "  label = label_pd_to_np(label)\n",
        "\n",
        "  return data, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88FaHVsSC90s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# let's generate data and train model\n",
        "classes = ['GBM', 'OV', 'LUAD', 'LUSC', 'PRAD', 'UCEC', 'BLCA', 'TGCT', 'ESCA', 'PAAD', 'KIRP', 'LIHC', 'CESC', 'SARC', 'BRCA', 'THYM', 'MESO', 'COAD', 'STAD', 'SKCM', 'CHOL', 'KIRC', 'THCA', 'HNSC', 'LAML', 'READ', 'LGG', 'DLBC', 'KICH', 'UCS', 'ACC', 'PCPG', 'UVM']\n",
        "shape = (150, 150)\n",
        "\n",
        "x, y = generate_dataset(data, label, shape)\n",
        "\n",
        "model = define_model(shape, y.shape[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOd94a3WJJAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define learning process\n",
        "\n",
        "sgd = optimizers.SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=True)\n",
        "#adam  = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "# weights = [174, 309, 576, 554, 550, 567, 427, 156, 196, 183, 323, 424, 310, 265, 1218, 122, 87, 495, 450, 474, 45, 606, 572, 566, 173, 171, 534, 48, 91, 57, 79, 187, 80]\n",
        "# weights = [ weight/11069 for weight in weights]\n",
        "\n",
        "# model.compile(loss = weighted_categorical_crossentropy(weights), optimizer = sgd, metrics=['accuracy'])\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = sgd, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsN2g1WuJMo5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7bdc969e-a22b-42d9-e87d-19b164d1e548"
      },
      "source": [
        "# train model\n",
        "\n",
        "history = model.fit(x, y, validation_split = 0.1, batch_size=32, epochs=80, verbose=1, shuffle=True)\n",
        "with open('/content/drive/My Drive/results/check', 'wb') as file_pi:\n",
        "  pickle.dump(history.history, file_pi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "312/312 [==============================] - 12s 38ms/step - loss: 3.8339 - accuracy: 0.0827 - val_loss: 3.0859 - val_accuracy: 0.1852\n",
            "Epoch 2/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 3.1657 - accuracy: 0.1406 - val_loss: 2.7950 - val_accuracy: 0.4110\n",
            "Epoch 3/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 2.9395 - accuracy: 0.2118 - val_loss: 2.4706 - val_accuracy: 0.4670\n",
            "Epoch 4/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 2.6654 - accuracy: 0.2929 - val_loss: 2.0711 - val_accuracy: 0.4851\n",
            "Epoch 5/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 2.3512 - accuracy: 0.3958 - val_loss: 1.6401 - val_accuracy: 0.5772\n",
            "Epoch 6/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 1.9970 - accuracy: 0.4956 - val_loss: 1.2557 - val_accuracy: 0.7173\n",
            "Epoch 7/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 1.6790 - accuracy: 0.5756 - val_loss: 1.0020 - val_accuracy: 0.7579\n",
            "Epoch 8/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 1.4044 - accuracy: 0.6436 - val_loss: 0.8510 - val_accuracy: 0.7940\n",
            "Epoch 9/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 1.2007 - accuracy: 0.6915 - val_loss: 0.7475 - val_accuracy: 0.7967\n",
            "Epoch 10/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 1.0303 - accuracy: 0.7303 - val_loss: 0.6700 - val_accuracy: 0.8257\n",
            "Epoch 11/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.9121 - accuracy: 0.7581 - val_loss: 0.5638 - val_accuracy: 0.8320\n",
            "Epoch 12/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.8080 - accuracy: 0.7834 - val_loss: 0.5037 - val_accuracy: 0.8618\n",
            "Epoch 13/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.7291 - accuracy: 0.8047 - val_loss: 0.4699 - val_accuracy: 0.8726\n",
            "Epoch 14/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.6709 - accuracy: 0.8217 - val_loss: 0.4648 - val_accuracy: 0.8654\n",
            "Epoch 15/80\n",
            "312/312 [==============================] - 11s 35ms/step - loss: 0.6276 - accuracy: 0.8261 - val_loss: 0.4244 - val_accuracy: 0.8717\n",
            "Epoch 16/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.5743 - accuracy: 0.8412 - val_loss: 0.3999 - val_accuracy: 0.8790\n",
            "Epoch 17/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.5434 - accuracy: 0.8490 - val_loss: 0.3881 - val_accuracy: 0.8790\n",
            "Epoch 18/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.5082 - accuracy: 0.8572 - val_loss: 0.4044 - val_accuracy: 0.8826\n",
            "Epoch 19/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.4888 - accuracy: 0.8624 - val_loss: 0.3588 - val_accuracy: 0.8871\n",
            "Epoch 20/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.4681 - accuracy: 0.8654 - val_loss: 0.3642 - val_accuracy: 0.8835\n",
            "Epoch 21/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.4450 - accuracy: 0.8689 - val_loss: 0.3584 - val_accuracy: 0.8862\n",
            "Epoch 22/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.4253 - accuracy: 0.8775 - val_loss: 0.3361 - val_accuracy: 0.8871\n",
            "Epoch 23/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.4097 - accuracy: 0.8802 - val_loss: 0.3505 - val_accuracy: 0.8943\n",
            "Epoch 24/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.3977 - accuracy: 0.8843 - val_loss: 0.3274 - val_accuracy: 0.8916\n",
            "Epoch 25/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.3809 - accuracy: 0.8843 - val_loss: 0.3169 - val_accuracy: 0.9006\n",
            "Epoch 26/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.3720 - accuracy: 0.8875 - val_loss: 0.3026 - val_accuracy: 0.9042\n",
            "Epoch 27/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.3570 - accuracy: 0.8925 - val_loss: 0.3061 - val_accuracy: 0.9042\n",
            "Epoch 28/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.3480 - accuracy: 0.8975 - val_loss: 0.3042 - val_accuracy: 0.9061\n",
            "Epoch 29/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.3403 - accuracy: 0.8960 - val_loss: 0.2929 - val_accuracy: 0.9024\n",
            "Epoch 30/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.3316 - accuracy: 0.8978 - val_loss: 0.3055 - val_accuracy: 0.9160\n",
            "Epoch 31/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.3287 - accuracy: 0.9012 - val_loss: 0.3008 - val_accuracy: 0.9015\n",
            "Epoch 32/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.3182 - accuracy: 0.8996 - val_loss: 0.2799 - val_accuracy: 0.9124\n",
            "Epoch 33/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.3050 - accuracy: 0.9058 - val_loss: 0.2801 - val_accuracy: 0.9151\n",
            "Epoch 34/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.3038 - accuracy: 0.9014 - val_loss: 0.2831 - val_accuracy: 0.9124\n",
            "Epoch 35/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.2956 - accuracy: 0.9069 - val_loss: 0.2901 - val_accuracy: 0.9124\n",
            "Epoch 36/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.2904 - accuracy: 0.9095 - val_loss: 0.2836 - val_accuracy: 0.9151\n",
            "Epoch 37/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.2826 - accuracy: 0.9125 - val_loss: 0.2580 - val_accuracy: 0.9196\n",
            "Epoch 38/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.2792 - accuracy: 0.9104 - val_loss: 0.2703 - val_accuracy: 0.9151\n",
            "Epoch 39/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.2770 - accuracy: 0.9130 - val_loss: 0.2708 - val_accuracy: 0.9169\n",
            "Epoch 40/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.2668 - accuracy: 0.9178 - val_loss: 0.2625 - val_accuracy: 0.9151\n",
            "Epoch 41/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.2601 - accuracy: 0.9159 - val_loss: 0.2510 - val_accuracy: 0.9214\n",
            "Epoch 42/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.2551 - accuracy: 0.9161 - val_loss: 0.2519 - val_accuracy: 0.9205\n",
            "Epoch 43/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.2545 - accuracy: 0.9172 - val_loss: 0.2644 - val_accuracy: 0.9187\n",
            "Epoch 44/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.2481 - accuracy: 0.9213 - val_loss: 0.2597 - val_accuracy: 0.9178\n",
            "Epoch 45/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.2499 - accuracy: 0.9206 - val_loss: 0.2464 - val_accuracy: 0.9169\n",
            "Epoch 46/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.2443 - accuracy: 0.9215 - val_loss: 0.2376 - val_accuracy: 0.9286\n",
            "Epoch 47/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.2403 - accuracy: 0.9215 - val_loss: 0.2439 - val_accuracy: 0.9259\n",
            "Epoch 48/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.2374 - accuracy: 0.9246 - val_loss: 0.2435 - val_accuracy: 0.9268\n",
            "Epoch 49/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.2334 - accuracy: 0.9243 - val_loss: 0.2417 - val_accuracy: 0.9241\n",
            "Epoch 50/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.2269 - accuracy: 0.9277 - val_loss: 0.2561 - val_accuracy: 0.9088\n",
            "Epoch 51/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.2294 - accuracy: 0.9245 - val_loss: 0.2263 - val_accuracy: 0.9304\n",
            "Epoch 52/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.2252 - accuracy: 0.9268 - val_loss: 0.2261 - val_accuracy: 0.9277\n",
            "Epoch 53/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.2202 - accuracy: 0.9288 - val_loss: 0.2438 - val_accuracy: 0.9088\n",
            "Epoch 54/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.2193 - accuracy: 0.9259 - val_loss: 0.2265 - val_accuracy: 0.9223\n",
            "Epoch 55/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.2153 - accuracy: 0.9275 - val_loss: 0.2327 - val_accuracy: 0.9241\n",
            "Epoch 56/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.2133 - accuracy: 0.9282 - val_loss: 0.2218 - val_accuracy: 0.9295\n",
            "Epoch 57/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.2115 - accuracy: 0.9292 - val_loss: 0.2317 - val_accuracy: 0.9259\n",
            "Epoch 58/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.2109 - accuracy: 0.9323 - val_loss: 0.2254 - val_accuracy: 0.9259\n",
            "Epoch 59/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.2117 - accuracy: 0.9267 - val_loss: 0.2312 - val_accuracy: 0.9313\n",
            "Epoch 60/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.2014 - accuracy: 0.9348 - val_loss: 0.2208 - val_accuracy: 0.9259\n",
            "Epoch 61/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.1969 - accuracy: 0.9338 - val_loss: 0.2207 - val_accuracy: 0.9304\n",
            "Epoch 62/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.1993 - accuracy: 0.9353 - val_loss: 0.2239 - val_accuracy: 0.9241\n",
            "Epoch 63/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.1972 - accuracy: 0.9337 - val_loss: 0.2166 - val_accuracy: 0.9332\n",
            "Epoch 64/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.1956 - accuracy: 0.9360 - val_loss: 0.2306 - val_accuracy: 0.9277\n",
            "Epoch 65/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.1949 - accuracy: 0.9320 - val_loss: 0.2206 - val_accuracy: 0.9313\n",
            "Epoch 66/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.1942 - accuracy: 0.9336 - val_loss: 0.2270 - val_accuracy: 0.9332\n",
            "Epoch 67/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.1882 - accuracy: 0.9357 - val_loss: 0.2164 - val_accuracy: 0.9277\n",
            "Epoch 68/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.1875 - accuracy: 0.9374 - val_loss: 0.2139 - val_accuracy: 0.9313\n",
            "Epoch 69/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.1831 - accuracy: 0.9400 - val_loss: 0.2156 - val_accuracy: 0.9250\n",
            "Epoch 70/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.1807 - accuracy: 0.9428 - val_loss: 0.2170 - val_accuracy: 0.9295\n",
            "Epoch 71/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.1805 - accuracy: 0.9386 - val_loss: 0.2220 - val_accuracy: 0.9259\n",
            "Epoch 72/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.1825 - accuracy: 0.9394 - val_loss: 0.2065 - val_accuracy: 0.9332\n",
            "Epoch 73/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.1826 - accuracy: 0.9393 - val_loss: 0.2165 - val_accuracy: 0.9304\n",
            "Epoch 74/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.1771 - accuracy: 0.9409 - val_loss: 0.2165 - val_accuracy: 0.9313\n",
            "Epoch 75/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.1722 - accuracy: 0.9401 - val_loss: 0.2178 - val_accuracy: 0.9250\n",
            "Epoch 76/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.1758 - accuracy: 0.9407 - val_loss: 0.2167 - val_accuracy: 0.9332\n",
            "Epoch 77/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.1743 - accuracy: 0.9442 - val_loss: 0.2035 - val_accuracy: 0.9350\n",
            "Epoch 78/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.1728 - accuracy: 0.9440 - val_loss: 0.2182 - val_accuracy: 0.9322\n",
            "Epoch 79/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.1676 - accuracy: 0.9430 - val_loss: 0.1989 - val_accuracy: 0.9304\n",
            "Epoch 80/80\n",
            "312/312 [==============================] - 11s 36ms/step - loss: 0.1708 - accuracy: 0.9431 - val_loss: 0.2026 - val_accuracy: 0.9322\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vJwWNFGTqRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load models and weights\n",
        "\n",
        "model_json = model.to_json()\n",
        "model.save(\"/content/drive/My Drive/results/model_without_featreduction_2D_1.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}